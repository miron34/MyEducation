# ML-вопросы

Линейные модели
Идея лин регрессии. Недостатки.
Лк признаков с весами. Первый недостаток - линейная пропорциональность признаков с выходами модели. Адекватная работа только со сложными признаками (закодированными, бинаризованными, исходя из бизнеса).
Аналитическое решение линейной регрессии. Его недостатки.
MSE = 1/n( ||X*w-y||^2 ) -> min
Grad(MSE, w) = 0
=> w = (Xt*X)^-1 * Xt * y - аналит решение
Xt*X  - матрица d*d, тогда О(d^3) - сложность обращения такой матрицы => очень долго
Метрики оценки задачи регрессии
Подход к решению задачи лин классификации. 
Метрики оценки Лин классификации. Достоинства и недостатки каждой метрики.
Идея лог рег. Преимущества. Недостатки.
Модель лин класс с выходами в виде вероятностей принадлежности к положит классу сигма(<w,x>). 
Похожие объекты ~ похожие вероятности. Фиксируем требование корректного оценивания вероятностей:
Е(L(y,b) | x) = p(y=+1 | x)
Расписав требование для лог лосса видим, что модель “b” действительно предсказ вероятности классов. 
Расписав ФК получим:
log(1+exp(-margin)), margin=y<w,x>.
Получаем то же, что и при простом «наивном» ограничении пороговой функции потерь для margin.
Основная задача - максимизация отступа 
Лучше для лог лосс, для вероятностей
Идея SVM. Преимущества. Недостатки.
Модель с основной идеей в максимизации разделяющей полосы между классами. Основная задача не margin->max, а наилучшее разделение классов.
Из постановки задачи: 
1/||w||^2 - ширина разделяющей полосы, будем ее максимизировать с условием что отступ должен быть >= 1 - e, e - возможные послабления.
Тогда задача:
||w||^2 +C/l * sum(e) -> min
Margin >= 1-e
e>=0
Тогда из последних двух
e = max(0, 1-M)
И задача:
1/l*sum(max(0, 1-M)) + 1/С*||w||^2 -> min
Также получаем ограничение пороговой функции для Лин класс.
SVM лучше для ROC, f1. У SVM хуже кривая калибровки вероятностей.
+хорошая классификация за счет роста раздел полосы
+мб удобно решать через задачу квадр прогр
-неустойчивость к шуму, выбросы становятся опорными объектами и сильно вредят
-необходимо подбирать С через cv
Почему SVM про опорные векторы?
M > 1: неинформативные объекты, лежащие глубоко в своем классе.
M = 1: опорные объекты, лежащие на разделяющей полосе внутри своего класса.
M < 1: опорные объекты-нарушители, лежащие в чужом классе
Благодаря теореме Каруша-Куна-Таккера о задачи нелинейного программирования, наша задача перетекает в задачу о поиске седловидный точке функции Лагранжа. Задача оптимизации лучше всего решается, базируясь на опорных векторах через методы спец для задач квадратичного прог.
Что характеризует параметр С в SVM?
Силу регуляризации. Чем больше С, тем меньше регуляризации.
Разница в подходах при многоклассовой классификации?
Для простых моделей, не умеющих работать с мультиклассом, есть два способа: 1vsAll, 1vs1
Метрики качества многоклассовой классификации?
Обычная accuracy, отдельные значения метрик по классам.
Микро усреднение - усредняем TP,FL,TN,FN, затем считаем метрики
Макро усреднение - наоборот считаем метрики, затем усредняем 
Почему L1 регуляризация отбирает признаки в отличие от L2? (КОНСПЕКТ)
Регуляризация - добавление в ФП штрафов за большие значения весов. Л1 - штрафы на л1 норму весов, Л2 - штрафы на л2 норму весов, ElasticNet - их объединение.
Основные практические отличия (два способа объяснения):
	1.	Через град спуск, который в основном движется в направлении производной. Поэтому при Л2-рег, когда веса уже малы, производная регуляризатора ~ значению параметра, будет вносить практически нулевой вклад в град шаг => веса будут иметь тенденцию стремиться к нулю, но его не достигать. У Л1-рег, напротив, производная всегда постоянна, кроме точки 0, в которой производная = 0. Поэтому она будет всегда стремить веса признаков к 0, соответсвенно отбирать их.
    2.	Графическое. В двумерном пространстве при Л1-рег ограничение на коэф-ты представляет собой ромб, в случае Л2 - круг. Необходимо минимизировать ФК при этом соблюсти ограничения на коэффициенты. С геом точки зрения нужно найти т. касания линии ФК и фигурой, соотв ограничению на коэффициенты. => в Л1-рег вероятность точка с большей вер-ю будет лежать на углах ромба (лежать на оси=нулевой коэф-т). В Л2-рег вер-ть того, что т. касания лежит на оси - крайне мала
Нужно ли штрафовать константу в регуляризации? Почему?
Нет, поскольку только за счет смещения порядок a(x) может достигаться порядка y. Иными словами только свободное смещение может сравнять мат ож для модели и таргетов
Мультиколлинеарность в линейных моделях. Чем опасна и что делать?
Мультиколлинеарность - ситуация, при которой два или более признаков имеют коэф корреляции выше заданного порога.
Это плохо в тех случаях, когда изначально предполагается что, фичи независимы друг от друга. Такая логика используется в линейных моделях, для которых корреляция признаков сильно портит картину. В лин мод каждый признак вносит индивидуальный вклад в модель. При наличии корр эффект коррелирующих признаков х1 и х2 будет трудно отличим, из-за этого будет сильно ухудшать я интерпретируемость модели. Нестабильность коэффициентов может увеличивать станд ошибку, отклонять т-распределение и приводить к переобучению.
Как лечить:
	⁃	Ручная очистка корр переменных
	⁃	Л1 и Л2 регуляризации, помогающие устремить к 0 веса корр признаков
	⁃	Сжать признаковое пространства с пом РСА (пропадет интерпретация)
——————————————————————-
Критерии сплита в деревьях?
Нужно считать каким то образом impurity
По тупому: 
H(R) = 1 - p(самый частый класс)
Джини: через доли классов
H(R) = sum(pk(1-pk)), k - классы
Энтропийный критерий:
H(R) = -sum(pk*log(pk)), k - классы
Выбираем предикат через максимизацию (по признаку и порогу) разницы impurity до и суммарную после 
Какова идея композиций моделей?
Идея исходит из того, что если взять N моделей обученных на N выборках из бустрепа, а затем расписать ошибку композиции, то видно, что ошибка уменьшается обратно пропорционально кол-ву моделей.
При дальнейшем разложении ошибки композиции на смещение и разброс (BVD), получаем 3 компоненты ошибки:
	⁃	Шум-ошибка лучшей модели(хар-ка данных)
	⁃	Смещение(bias) - отклонение средней модели от лучшего прогноза (хар-ка семейства моделей)
	⁃	Разброс(variance) - чувствительность единичной модели к изменениям обуч выборки
Хотим добиться композицией маленькое смещение при маленьком разбросе. Анализируя известные виды моделей:
	⁃	композиция лин моделей дает высокое смещение и маленький разброс => не подходит
	⁃	неглуб деревья смещение лучше лин мод и низкий разброс
	⁃	глуб деревья смещения ≈ 0, но большой разброс из-за переобучения 
=> композиции это круто
Идея бэггинга. Отличие случайного леса от бэггинга?
Бэггинг - композиция усредненных моделей, построенных бустрепом.
Далее улучшим. Хотим добиться композицией маленькое смещение при маленьком разбросе. 
	⁃	Смещение композиции = смещении базовой модели
	⁃	Разброс композиции = 1/N * разброс баз модели + N(N-1)/N^2 * ковариация двух моделей, построенный на бустрепе
Тогда:
	⁃	Глубину деревьев побольше для низкого смещения
	⁃	Макс независимость баз моделей для низкой ков баз моделей (каждая выборка из бустрепа, лучший предикат в каждой вершине выбираем из случайного подмножества признаков)
Получили случайный лес! (Единственный гиперпараметр - число деревьев)
Почему случайный лес не переобучается?
Тк при достаточном числе деревьев, достигается минимальный разброс:
	⁃	За счет зануления разброса базовых моделей
	⁃	Минимизация веса от ковариация баз моделей за счет случайного выбора признакового пространства 
Различие градиентного бустинга и обычного? Откуда берется градиент? Различия?
Идея классического бустинга (адаптивного бустинга AdaBoost) - в создании композиции из последовательно обучаемых деревьев. Где каждая новая модель обучается на ошибках предыдущих.
Но такая идея не учитывать вид функции потерь. Для MSE все хорошо работает:
MSE(yi, a(n-1)(xi) + bn(xi)) = MSE(yi - a(n-1)(xi), bn(xi))Для других функций потерь будет грустнее.Поэтому существует град бустинг, в котором обучение текущей модели ведется на антиградиенте предыдущей композиции:
Учимся предсказывать:  si = dL(yi, z)/ dz при z=a(n-1)(xi)
Зачем так было делать? Град бустинг намного более устойчив к выбросам в отличие от адаптивного и более гибок с точки зрения функции потерь
Можно ли использовать лин модель в качестве базовой в бустинге?
Можно, но в итоге получим также лин модель, тк ЛК лин моделей = лин модель
Что с переобучением в град бустинге?
	⁃	В современных реализация GB стоят штрафы за большие прогнозы в листьях, что регуляризует модель
	⁃	Понизить глубину базовых деревьев
	⁃	Ввод learning rate - длины шага, чтобы давать меньше веса каждой модели
	⁃	Стохастический GB - обучение очередной модели bn на случ подвыборке
В GB используются неглубокие деревья, тк они понижают разброс, и в концепции бустинга итоговая модель все также имеет низкое смещение
Что там с BVD в бустингах? Отличие от случайного леса?
Как производить отбор признаков в бустинге и в случ лесе?
Уверенность модели бустинг-регрессора?
Чтобы оценить уверенность предсказаний в бустинге, надо посмотреть на предсказания каждого дерева в бустинге. Чем раньше мы сходимся к правильному ответу (или выходим на асимптотику), тем более уверенным себя чувствует бустинг. Если же от дерева к дереву модель шатает, то объект скорее всего новый и неудобный для модели.
Prediction Intervals в Бустинге
Нужно для установки валидного интервала
Различие реализаций бустингов между собой?
Современные реализации бустингов работают в отличие от классик град буст использую не только 1ю, но и 2ю производную функции потерь, тем самым учитывая выпуклость/кривизну ФП.Три основные реализации (отличия в форме реш деревьев):
	⁃	LGBM - “делим вершину с наилучшем скором” и критерий останова - макс число вершин. Пример работы: было N листьев, разбиваем одну из них, получаем N+1 лист, воспринимаем все N+1 листов одинаково, выбираем какой из всех будем делить следующим. Таким образом деревья получаются очень асимметричными.
	⁃	XGB - “строим дерево последовательно по уровням до достижения максимальной глубины”. То есть пока мы не разобьем листы N уровня полностью, к N+1 не переходим. XGBoost деревья “стремятся” быть симметричными по глубине. Деревья получаются почти что полными бинарными.
	⁃	CatBoost - “все вершины одного уровня имеют одинаковый предикат” - сильно увеличивает скорость инференса и добавляет регуляризация - устойчивость к выбросам. Критерий останова - макс глубина дерева
Блендинг. Стэкинг. Отличия
Бэггинг и бустинг - некая сумма моделей (a(x) = sum(jn * bn(x)), где jn = 1 в бустинге и 1/N в бэггинге)
Теперь на выходы каждой из N моделей хотим повесить метамодель.Причем очень важно обучать метамодель на выборке, отличающейся от выборки для обучения базовых моделей (иначе если баз модель переобучилась, то и метамодель сразу же переобучится)
Блэндинг - разбить обучение выборку Х на непересекающиеся Х1 и Х2. На Х1 обучаем базовые модели, на Х2 - метамодель
Стэкинг - разбить обучение выборку Х на K неперсек подвыборок. Текущая модель bnk(x) на Х\Хк => обучили N*K моделей.
На каждом Xk обучаем метамодель, и каждый раз берем модели, не обучавшиеся на XkБлагодаря таким подходам можно навешивать сложную логику для объединения моделей, а также использовать модели из разных семейств.
——————————————————————-
Метрики качества кластеризации
	⁃	Минимизация внутрикластерного расстояния
	⁃	Максимизация межкластерного расстояния
	⁃	Индекс Данна
Виды кластеризаций
	⁃	Метрическая кластеризация (K-means). Случайно иниц центра кластеров С1,..,Скшаг а) фикс с1,..,ск: подкручиваем параметры а(х)шаг б) фикс а(х): подкручиваем с1,..скПовторяем до сходимости. Хорошо работает при евклидовом расстоянии. К-гиперпараметр. Строим график внутриклас расс-я от К, точка локтя выхода на плато - лучшее К
	⁃	Плоскостная кластеризация (DBSCAN)
	⁃	Графовые 
	⁃	Иерархические
Реальные кейсы использование кластеризации
⁃	В антифроде: при наличии готовых признаков отучить кластеризацию и обнаружить кластера сильно далекие от основного сгустка объекто. Пример из Яндексе, отдел рекламы: хорошие пользователи + все их действия + автоэнкодер = эмбединги для хороших пользователей с соотв фичами. Всех остальных пользователей прогоняем через этот автоэнкодер, получаем эмбединги для всех. В этом пространстве делаем трюк с кластеризация и ищем фродеров
	⁃	Для сегментации. Допустим хотим показывать разную рекламу разным пользователям => можно их умно сегментировать через кластеризацию 
	⁃	Получить новые признаки для модели, как метки кластеров
	⁃	
Виды методов уменьшения размерности (MDS, t-SNE, PCA)
PCA: 
	⁃	Хотим уменьшить признаковое пр-во, сост новые комп-ты (как ЛК старых: zk = X * uk, U - матрица весов) с макс возможной дисперсией 
	⁃	Задача для поиска очередной компоненты: (var(zk)->max, новое uk перп всем предыдущ uj, ||uk||=1)
	⁃	После решения получим: Xt*X*uk=L*uk задачу на максимизацию СЗ L. 
	⁃	Очередная j-я комп-та в новом разложении zj = X*uj, где uj СВ для XtX, соотв j-му по величине СЗ Lj этой матрицы 
	⁃	СЗ Lj характеризует величину дисперсии этой компоненты
	⁃	Доля объясненной дисперсии для d<D: (L1+…+Ld) / (L1+…+LD), где Lk - СЗ для К-й компоненты 
MDS (метод многомерного скалирования):
	⁃	Хотим нарисовать многомерную выборку в 2D, сохраняя попарные расстояния
	⁃	Идея плохая, тк заведомо неразрешимая
	⁃	Новые к-ты не явл функцией от начальных, те не имеют к ним никакого прямого отношения => нельзя использовать как новые признаки
t-SNE:
	⁃	Хотим нарисовать многомерную выборку в 2D, сохраняя попарные пропорции.
	⁃	Составим распределения: p(i|j) на начальных признаках и q(i|j) на конечных. Распределения базируются на близостях объектов
	⁃	Максимизируем дивергенцию Кульбака-Лейблера этих распределений как меру их похожести (параметры = z1,…,zl из R2)
	⁃	Новые к-ты не явл функцией от начальных, те не имеют к ним никакого прямого отношения => нельзя использовать как новые признаки
Можно ли использовать новые координаты из t-SNE, PCA как признаки для новой модели?
	⁃	PCA: можно. Новые компоненты являются ЛК старых
	⁃	t-SNE: нельзя. Новые к-ты не явл функцией от начальных, те не имеют к ним никакого прямого отношения => нельзя использовать как новые признаки
——————————————————————-
Рек системы
Баесовские методы мл
SVD разложение матрицы. СВ и СЗ матрицы, как искать? Где применять?
——————————————————————-
Переобучение. Чем плохо? Как лечить?
«Подгоняемся» под трен выборку. Модель теряет главное свойство - обобщающую способность. Лечим:
	⁃	Махинации с данными (увеличение тренировочной выборки: или прямое, или синтетическое через какие ниб аугментации)
	⁃	Упрощение моделей (число слоев/нейронов в сетях, число листьев/глубину в деревьях и тд)
	⁃	Добавление случайностей в модель(Дропаут или ДропКоннект (то же что и дропаут, но убираем не нейроны а их связи))
	⁃	Корректировка функции потерь (добавление L1, L2 регуляризаций и может быть чего посильнее)
	⁃	Более ранняя остановка обучения 
	⁃	Ансамблирование моделей по типу бэггинга. Увеличиваем кол-во моделей обученных на бустрепе и сохраняем их независимость => разброс ~ 1/N + N(N-1)/N^2*ковариация баз мод, тогда при сохр независимости и увелич числа разброс (возможное переобуч) будет уменьшаться
	⁃	Уменьшение размерности обуч выборки через PCA. Помогает избавить от мультиколлинеарности, мешающей норм обучению линейных моделей
Как бороться с дисбалансом классов?
Чем плох? Где плохо? Как поможет PRC кривая?
Oversampling, undersampling, учет в метрике качества, синтетические данныеЧто делать с пропусками в данных? Где это критично?
	⁃	удаление объектов с нулевыми признаками (можем многое потерять)
	⁃	удаление признаков с большим кол-вом нулей
	⁃	заполнение средним, модой, медианной 
	⁃	заполнение нулем для непр фичи и новой «нулевой» категорией для кат фичи.
	⁃	любое более сложное интерполирование
	⁃	через мл: найти по признакам самых близких и интерполировать 
Что делать с выбросами?
	⁃	3 сигмы
	⁃	Правило IQR - про отступ в 1.5*IQR
	⁃	Обучить модель
    Нормализация. Для каких моделей нужна и почему?
Нормализация нужна для того, чтобы воспринимать все признаки «равноправно», чтобы нивелировать влияние масштаба.
Влияние масштабов признаков особенно характерно для алгоритмов:
	⁃	distance-based (knn, k-means)
	⁃	PCA
	⁃	обучающихся градиентным спуском (нормальные шаги по одной оси = слишком большие или слишком маленькие шаги по другой оси). Разные масштабы признаков «вытягивают» линии уровня в разные стороны => град спуск затормаживается и может не дойти до лок минимума.
Для деревьев нормализация не играет никакой роли. В деревьях производится независимый выбор фичи в предикат в каждом листе и разделение идет только по текущей фиче.
Разница нормализации и стандартизации. Применение
Стандартизация - приведение данных к распределению с матож=1, дисп=1.
Нормализация - привидение в масштаб от 0 до 1.
Решают одну и ту же проблему размерностей, но с нек различиями. Стандартизация лучше справляется с выбросами. Также она предпочтительнее, когда мы понимаем что признак имеет распр близкое к нормальному. К тому же многие алгоритмы лучше работают с распределениями близкими к нормальному, те стандартизация предпочтительнее 
Методы работы с категориальными фичами. 
	⁃	ван хот
	⁃	Таргет кодирование
Что такое проклятие размерности?
Проблема, связанная с экспоненциальным возрастанием количества параметров при увеличении размерности пространства. Также помимо усложнения моделей объем данных, требуемых для надежного прогноза, также растёт по экспоненте (симуляция для расчета числа Пи при фикс кол-ве точек и увеличивающейся размерности) 
В следствие имеем сильное ухудшение производительности и потерю информативности
Как оценить важность признака в модели?
	⁃	можно выкинуть признак и оценит изменение качества модели с и без него
Какие виды кросс-валидаций бывают? Недостатки?
Как понять на сколько фолдов разбивать?
Чем больше разброс, тем менее чувствительная схема валидации 
Может ли быть precision, recall, f1 = 0, а roc-auc=1? А наоборот?
Как проверить, что модель даст прирост в кач-ве перед внедрением?
(валидация, дов интервалы, проверка гипотез)
Методы оптимизации? Преимущества?
Проблема холодного старта?
Вероятности 
Т критерий 
Аб тест, Аа тест
Дов интервал 
P-value, Нулевая гипотеза
Зачем нужен произв функция моментов
Непарам стат тесты
Что оптимизирует MSE? Какие предположения мы делаем? А если с модулями?
Какой баесовский и алгебраический смысл л1, л2 рег?
Можно ли убрать первое дерево в град буст? В случ лесе?
	⁃	в бустинге нельзя, первое дерево самое важное, тк деревья обучаются последовательно и прогнозы без его вклада не будут иметь смысла
	⁃	В случайном лесе можно, поскольку деревья обучаются независимо и вклад одного дерева в общий прогноз мал, относительно общего 
Можно ли иниц нейронку нулями?
Нет, поскольку производная от лосса всегда будет нулевой => град спуск не начнется
Почему чаще всего сетку усложняют добавляя слои, а не расширяя слои в ширину?
Для извлечения более сложных, высокоуровневых признаков
Какие основные архитектуры используются для задач CV классификации? Сегментации?
	⁃	классификация: resnet, VGG подобные. У resnet особенность - skip connections: проброс предыдущих выходов слоев дальше (для того, чтобы градиенты не затухали так быстро около первых слоев)
	⁃	сегментация: Unet подобные. Unet работает похожим образом на декодер и энкодер: сначала сильно сжимая пр-во, а потом, разжимая его. Также там есть skip-connections.
Архитектуры для решения NLP задач:
Как бороться с очень долгим инференсом в глубоких тяжелых сетках?
	⁃	дистилляция: пытаемся обучить более легкую модель, инференс соотв тоже станет быстрее
	⁃	квантизация: заменяем типы весов float на int. За счет этого ускорение обработки инференса.
Явления градиентного взрыва и градиентного затухания.
	⁃	Взрыв: при проходе через глуб сетку может нарастать градиент и тогда повышается вероятность сделать слишком большой шаг в град спуске и перескочить минимум.
	⁃	Затухание: обратная ситуация, когда градиент практически уйдет в ноль для первых слоев сетки. Обучение этих слоев практически остановится.
    Как понять, что один алгоритм лучше другого? Сколько наблюдений необходимо для этого?
Какие методы оценки качества лучше для несбалансированной выборки?
Поч плохо рок аук
Поч хороши ф1 и прс кривая
Когда лучше применять каждую из метрик в задаче классификации?
	⁃	Accuracy: доля верно предсказанных ответов. Неприменима при несбалансированной выборке, поскольку константа мажоритарного класса даст высокий скор. Нужно подбирать порог, тк оцениваются прогнозы, а не скор. Можно использовать, если: нет дисбаланса и каждый класс имеет равный вес. Очень хорошо интерпретируема
	⁃	F1-score (beta): гармоническое среднее precision и recall с соотв пропорциям между ними. Больше beta => больше вес recall. Оценивает прогнозы => нужно подбирать класс. Устойчива к дисбалансу за счет регулировки пропорций precision и recall.
	⁃	Roc-Auc:…………. Плохо в имбалансе, если классы не одинаково важные. У нас в сбсж норм, тк оба класса одинаково важные, несмотря на дисбаланс классов
	⁃	
Как объяснить рок аук бизнесу?
Как правильно выбрать метрику качества в бин классификации?
Отбор признаков
	⁃	корреляция пирсона
	⁃	По весам лог рег
	⁃	Важности признаков на древооьрр модели 
	⁃	One feature out
	⁃	Найти лучшие два признака, след лучший и тд
	⁃	Логика
	⁃	Визуализация относ таргета
