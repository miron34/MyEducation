{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВНИМАНИЕ!\n",
    "\n",
    "Следующее задание крайне рекомендуется выполнять в Google Colab, чтобы обеспечить отсутствие проблем с соединением при скачивании датасета, а также чтобы обеспечить скорость при обучении нейросети. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "На этом семинаре мы научимся очень быстро обучать нейросеть на сложную задачу классификации изображений, используя очень простой приём, именуемый fine tuning'ом. \n",
    "\n",
    "Для начала скачем датасет. На этот раз мы научим нейронку отличать кошечек от собачек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip && unzip kagglecatsanddogs_3367a.zip > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим несколько битых изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./PetImages/Cat/666.jpg ./PetImages/Dog/11702.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет разделим средствами pytorch'a на трейн и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor \n",
    "\n",
    "dataset = ImageFolder(\n",
    "    \"./PetImages\", \n",
    "    transform=Compose(\n",
    "        [\n",
    "            Resize((224, 224)), \n",
    "            ToTensor(), \n",
    "            Normalize((0.5, 0.5, 0.5), (1, 1, 1)), \n",
    "        ]\n",
    "    )\n",
    ")\n",
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    dataset, \n",
    "    [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем из скачанных датасетов даталоадеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят картинки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.random.choice(glob.glob(\"./PetImages/*/*.jpg\"))\n",
    "plt.imshow(plt.imread(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кошки и собаки это конечно хорошо, вот только обучение модели, которая будет хорошо работать на этом датасете может оказаться очень долгим...\n",
    "\n",
    "Однако картинки, которые мы сегодня рассмотрим оказываются очень похожими на картинки из огромного датасета ImageNet. Задача, которую мы сегодня рассмотрим, называется Transfer Learning -- в русскоязычной литературе иногда можно встретить термин \"обучение с переносом знаний\". Знания мы действительно переносим -- от сети, которая хорошо работает на одном датасете (ImageNet) к другим данным (к датасету Cats vs Dogs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим уже обученную сеть\n",
    "\n",
    "В библиотеке `torchvision` имплементировано не только большое множество моделей (всевозможные ResNet'ы, Inception, VGG, AlexNet, DenseNet, ResNext, WideResNet, MobileNet...), но и загружены чекпоинты обучения этих моделей на ImageNet. Однако для датасета Cats vs Dogs такая штука является роскошью..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "# Загрузить предобученную сеть -- pretrained=True\n",
    "model = resnet18(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задаче transfer learning'a мы заменяем последний слой нейросети на линейный с двумя выходами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже несколько функций, которые мы уже видели в предыдущих семинарах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    return_losses=False,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    model = model.to(device).train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_losses = []\n",
    "    total_predictions = np.array([])#.reshape((0, ))\n",
    "    total_labels = np.array([])#.reshape((0, ))\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for images, labels in data_loader:\n",
    "            # Move Batch to GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = criterion(predicted, labels)\n",
    "            # Update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # Update descirption for tqdm\n",
    "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
    "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
    "            num_batches += 1\n",
    "            all_losses.append(loss.detach().item())\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
    "    if return_losses:\n",
    "        return metrics, all_losses\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def validate(model, data_loader, criterion, device=\"cuda:0\"):\n",
    "    model = model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    total_predictions = np.array([])\n",
    "    total_labels = np.array([])\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = criterion(predicted, labels)\n",
    "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
    "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
    "            num_batches += 1\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    epochs,\n",
    "    train_data_loader,\n",
    "    validation_data_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device=\"cuda:0\"\n",
    "):\n",
    "    all_train_losses = []\n",
    "    epoch_train_losses = []\n",
    "    epoch_eval_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        # Train step\n",
    "        print(f\"Train Epoch: {epoch}\")\n",
    "        train_metrics, one_epoch_train_losses = train_epoch(\n",
    "            model=model,\n",
    "            data_loader=train_data_loader,\n",
    "            optimizer=optimizer,\n",
    "            return_losses=True,\n",
    "            criterion=criterion,\n",
    "            device=device\n",
    "        )\n",
    "        # Save Train losses\n",
    "        all_train_losses.extend(one_epoch_train_losses)\n",
    "        epoch_train_losses.append(train_metrics[\"loss\"])\n",
    "        # Eval step\n",
    "        print(f\"Validation Epoch: {epoch}\")\n",
    "        with torch.no_grad():\n",
    "            validation_metrics = validate(\n",
    "                model=model,\n",
    "                data_loader=validation_data_loader,\n",
    "                criterion=criterion\n",
    "            )\n",
    "        # Save eval losses\n",
    "        epoch_eval_losses.append(validation_metrics[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте объект лосса и оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer =  # YOUR CODE. It must optimize only across fully connected layer\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit(model, 5, train_dataloader, test_dataloader, optimizer, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим на одну эпоху обучения уходит порядка двух минут, и уже после одной эпохи получается приемлемое качество. Давайте проинициализируем модель с нуля и попробуем обучить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full = resnet18(pretrained=False)\n",
    "model_full.fc = nn.Linear(512, 2)\n",
    "optimizer =  # YOUR CODE. It must optimize across all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit(model_full, 5, train_dataloader, test_dataloader, optimizer, criterion, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вопрос__. Почему при обучении полной модели получается так, что время на одну эпоху почти такое же?\n",
    "\n",
    "Рекомендуем подумать на этим вопросом самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, на transfer learning'e нейросеть сходится очень быстро. Значительно быстрее, чем инициализированная с нуля. Можно с уверенностью говорить, что transfer learning -- очень полезная техника."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial атаки.\n",
    "\n",
    "Такая вещь, как атаки на нейросеть крайне важны для учёта при разработке. Существует много методов как их генерации, так и защиты от них. Мы рассмотрим сегодня базовые концепты, чтобы дать понимание происходящего.\n",
    "\n",
    "Можем назвать adversarial атакой генерацию такого примера, который не отличим глазом от настоящего, но нейросеть будет ОЧЕНЬ уверена в том, что этот пример из другого класса. Сейчас мы попробуем сгенерировать такую собачку, что нейросеть будет уверена, что это котик.\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/fgsm_panda_image.png\">\n",
    "\n",
    "Сегодня мы рассмотрим пример Fast Gradient Sign Attack (FGSM, почему там буква M в конце -- чёрт его знает...). Идея очень простая. Оказывается, что если мы через обученную нейросеть посчитаем градиент по исходной картинке, посчитаем  его знак и прибавим, умножив на маленькое число, модель подумает, что это картиинка другого класса.\n",
    "\n",
    "Для того, чтобы нам посчитать градиент по входу, нам предстоит \"разморозить\" все её граиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # YOUR CODE\n",
    "    # DO EXACTLY WHAT IS WRITTEN ON THE ABOVE IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем из датасета случайную картинку с кошечкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 1\n",
    "while cl == 1:\n",
    "    i = np.random.randint(0, len(train_set))\n",
    "    cl = train_set[i][1]\n",
    "    image = train_set[i][0]\n",
    "    image = image.to(device)\n",
    "    # Разрешим вычисление градиента по картинке\n",
    "    image.requires_grad = True\n",
    "    \n",
    "    pred = model(image[None])\n",
    "    predicted_label = pred.argmax(1).item()\n",
    "    confidence = pred.softmax(1)[0][predicted_label]\n",
    "\n",
    "\n",
    "# красиво рисуем\n",
    "if predicted_label == 1:\n",
    "    plt.title(\"Dog, confidence = %0.4f\" % confidence.item());\n",
    "else:\n",
    "    plt.title(\"Cat, confidence =  %0.4f\" % confidence.item());\n",
    "plt.imshow(image.cpu().detach().numpy().transpose((1, 2, 0)) + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое интересное начинается тут. Вычислим градиент функции потерь по картинке при помощи вызова .backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(pred, torch.tensor(cl).reshape((1,)).to(device))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведём атаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.007\n",
    "\n",
    "attack = fgsm_attack(image, eps, image.grad)\n",
    "pred = model(attack[None])\n",
    "predicted_label = pred.argmax(1).item()\n",
    "confidence = pred.softmax(1)[0][predicted_label]\n",
    "\n",
    "if predicted_label == 1:\n",
    "    plt.title(\"Dog, confidence = %0.4f\" % confidence.item());\n",
    "else:\n",
    "    plt.title(\"Cat, confidence =  %0.4f\" % confidence.item());\n",
    "plt.imshow(attack.cpu().detach().numpy().transpose((1, 2, 0)) + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
