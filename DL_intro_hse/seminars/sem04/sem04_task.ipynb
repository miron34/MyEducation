{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполненный ноутбук в колабе: https://colab.research.google.com/drive/1dqq5e-c_yMrpiKpXGn4NzFQ0_3OOSCwO?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUJcEdalKlZn"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD68Ub9hKlZy"
   },
   "source": [
    "## Методы оптимизации\n",
    "Как вам показали на лекции, большинство методов машинного обучения сводятся к простому поиску параметров, который бы минимизировал ошибку на тренировочной выборке:\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{x \\in X_{test}} L(p_{\\theta}(x), y)\n",
    "$$\n",
    "Здесь:\n",
    "* $L$ - некоторый лосс,\n",
    "* $p_{\\theta}$ - нейронная сеть с параметрами $\\theta$,\n",
    "* $X$ - данные для обучения,\n",
    "* $y$ - ответы\n",
    "\n",
    "Напишем алгоритм для поиска минимума некоторой функции\n",
    "$$\n",
    "f(x) = x^{3} + 2x^{2} + 2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "6RDPRKKHKlZ0",
    "outputId": "ad30ce72-29b4-48c9-b153-32e9c8286553"
   },
   "outputs": [],
   "source": [
    "# Наша функция f(x)\n",
    "func = lambda x: x ** 3 - 2 * x ** 2 + 2\n",
    "\n",
    "# Производная функции f(x)\n",
    "d_func = lambda x: 3 * x ** 2 - 4 * x\n",
    "\n",
    "# Сделаем массив из 1000 элементов от -3 до 3\n",
    "x = np.linspace(-3, 3, 1000)\n",
    "\n",
    "# Определим границы по y для графика\n",
    "plt.ylim([-1, 3])\n",
    "plt.plot(x, func(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYQ4OyiUKlZ4"
   },
   "source": [
    "Определим функцию для оптимизации $f(x)$, которая должна принимать на вход learning rate, максимальное количество итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQ_QI8CiKlZ5"
   },
   "outputs": [],
   "source": [
    "def find_minimum_first_order(\n",
    "    learning_rate=0.01,\n",
    "    eps=1e-4,\n",
    "    max_iterations=1000,\n",
    "    anneal_learning_rate=None\n",
    "):\n",
    "    i = 0\n",
    "    x_old, x_new = 0, 2\n",
    "    # Будем сохранятся обновлённые значения x и y\n",
    "    x_list, y_list = [x_old], [func(x_old)]\n",
    "    if not anneal_learning_rate:\n",
    "        anneal_learning_rate = lambda lr, step: lr\n",
    "    # TODO:\n",
    "    # Your code here\n",
    "    # --------------\n",
    "    # With these commands append new values to lists\n",
    "    # x_list.append(x_new)\n",
    "    # y_list.append(func(x_new))\n",
    "    # --------------\n",
    "    print(\"Найденный локальный минимум:\", x_new)\n",
    "    print(\"Количество шагов:\", len(x_list))\n",
    "    # Визуализируем сходимость\n",
    "    plt.figure(figsize=[6, 4])\n",
    "    plt.ylim([-3, 8])\n",
    "    plt.scatter(x_list, y_list, c=\"r\", edgecolors='k')\n",
    "    plt.plot(x_list, y_list, c=\"r\")\n",
    "    plt.plot(x, func(x), c=\"b\")\n",
    "    plt.title(\"Descent trajectory\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBakKAc4KlZ8"
   },
   "source": [
    "Попробуем различные learning rate и посмотрим на поведение оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "kBe4cH6vKlZ9",
    "outputId": "c7b55c92-f733-40c5-be0a-4023f3896047"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6qHwvrQKlaA"
   },
   "source": [
    "Слишком мало, будем очень долго идти к локальному минимуму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "4fJFR4SlKlaB",
    "outputId": "b9f7b5c7-f84c-4f6a-b4e0-01d5620cb0fb"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyeqRTitKlaF"
   },
   "source": [
    "Уже лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "AEX-iPPJKlaF",
    "outputId": "ce59562a-8aed-4651-a8e4-7b9ee029e2d0"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "6Xz1B6hyKlaI",
    "outputId": "0450cf6e-879a-4eb1-8b16-28ec1f022d33"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTTbzvS0KlaM"
   },
   "source": [
    "Ууупс, получили Overflow. Значит learning rate слишком большой. Хотя большой learning rate опасен возможностью overflow у него есть ряд преимуществ. Чем больше темп обучения, тем большие расстояния мы преодолеваем за один шаг и тем выше вероятность быстрее найти хорошее пространство локальных минимумов.\n",
    "\n",
    "Хорошая стратегия — начинать с достаточно большого шага (чтобы хорошо попутешествовать по функции), а потом постепенно его уменьшать, чтобы стабилизировать процесс обучения в каком-то локальном минимуме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "itCkyBdaKlaN",
    "outputId": "366052e6-d2c3-4628-b81e-11edc4c0b054"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.6, anneal_learning_rate=lambda lr, step: 0.3 * lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSMWbov7ZrSQ"
   },
   "source": [
    "# Описание алгоритмов градиентного спуска\n",
    "\n",
    "### SGD\n",
    "SGD - этот же самый gradient descent, что мы рассматривали ранее, вот только подсчёт градиентов производится не по всему множеству данных, а по отдельно взятому сэмплу. Очевидно, такая оптимизация будет очень шумной, что усложнит обучение модели. Поэтому обычно используют MiniBatch-SGD, где вместо одного сэмпла мы берём $k$ семплов. У такого подхода есть несколько плюсов:\n",
    "\n",
    "* ниже variance в сравнении с обычным SGD, что приводит к более стабильному процессу оптимизации\n",
    "* хорошо работает с DL библиотеками, так как теперь мы работаем с матрицами\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "w &=& w - \\eta \\times g\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "### SGD with Momentum\n",
    "\n",
    "![Momentum.png](Momentum.png)\n",
    "\n",
    "Попытаемся добавить SGD эффект инерции. Теперь, вместо того чтобы двигаться строго в направлении градиента в каждой точке, мы стараемся продолжить движение в том же направлении, в котором двигались ранее. То есть у нашей точки, которая спускается по многомерной поверхности, появляется импульс (momentum), который контролируется при помощи параметра $\\alpha$. Он определяет какую часть прошлого градиента мы хотим использовать на текущем шаге.\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g_{t} &=& \\alpha g_{t-1} + \\eta \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "w &=& w - \\eta \\times g\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "## Адаптивные варианты градиентного спуска\n",
    "Во всех предыдущих алгоритмах у нас был фиксированный learning rate. Начиная с Adagrad у нас будет идти алгоритмы, которые подстраивают learning rate в зависимости от обучения. Они называются адаптивными вариантами градиентного спуска.\n",
    "\n",
    "Адаптивные варианты градиентного спуска подстраивает темп обучения таким образом, чтобы делать большие или маленькие обновления отдельных параметров. Например, может так сложиться, что некоторые веса близки к своим локальным минимумам, тогда по этим координатам нужно двигаться медленнее, а другие веса ещё только в середине, значит их можно менять гораздо быстрее. Подобные методы часты приводят к более обоснованной модели и сходятся гораздо быстрее.\n",
    "\n",
    "### Adagrad\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "s &=& s + diag(gg^{T}) \\\\\n",
    "w &=& w - \\frac{\\eta}{\\sqrt{s+eps}} \\odot g\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "Теперь нам не нужно сильно волноваться о правильном подборе $\\eta$, так как $s$ контролирует скорость обучения для каждого параметра.\n",
    "\n",
    "### RMSprop\n",
    "У Adagrad есть сильный минус. $s$ - всегда положительна и постоянно растёт во время обучения, что приводит к ситуации, когда у нас learning rate становится слишком маленький, и мы перестаём учиться. RMSprop исправляет эту проблему при помощи экспоненциального сглаживания\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "s &=& \\rho s + (1 - \\rho) diag(gg^{T}) \\\\\n",
    "w &=& w - \\frac{\\eta}{\\sqrt{s+eps}} \\odot g\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "### Adam\n",
    "Добавим не только моменты второго порядка, но и первого при обновлении параметров\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "m &=& \\beta_1 m + (1 - \\beta_1) g \\\\\n",
    "v &=& \\beta_2 v + (1 - \\beta_2) diag(gg^{T}) \\\\\n",
    "\\hat{m} &=& \\frac{m}{1 - \\beta_1^{t}} \\\\\n",
    "\\hat{v} &=& \\frac{v}{1 - \\beta_2^{t}} \\\\\n",
    "w &=& w - \\frac{\\eta}{\\sqrt{\\hat{v} + \\epsilon}} \\odot \\hat{m}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "### Схема\n",
    "<div>\n",
    "<img src=\"Modifications.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeCXawXsKlaX"
   },
   "source": [
    "# PyTorch Optimizer\n",
    "Очевидно, что для своих нейронных сетей не нужно каждый раз писать свой алгоритм и за вас уже сделаны все самые популярные методы. Их можно найти в **torch.optim**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "8oraXo9DKlaX",
    "outputId": "dffa1849-24b5-4ce1-c1ef-e7b35f64a7ea"
   },
   "outputs": [],
   "source": [
    "[elem for elem in dir(torch.optim) if not elem.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Xsq3M5VKlaa"
   },
   "source": [
    "Основные функции PyTorch Optimizer:\n",
    "* __step__ - обновление весов модели\n",
    "* __zero_grad__ - занулить веса модели (по умолчанию градиенты в PyTorch аккумулируются) ~ `for each param in params: param.grad = None`\n",
    "* __state_dict__ - получить текущее состояние Optimizer. Для адаптивных методов тут будут храниться аккумулированные квадраты градиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWG6WICUKlaa"
   },
   "source": [
    "## Как сделать instance PyTorch Optimizer?\n",
    "Достаточно передать параметры модели (их можно получить при помощи функции `parameters()`) и гипер-параметоры для метода оптимизации.\n",
    "\n",
    "Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLLI3GbM89kb"
   },
   "outputs": [],
   "source": [
    "?torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "BDgqvgVJKlaa",
    "outputId": "ec998e70-e2b8-499d-c329-1bc65c187156"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(1, 1)\n",
    "list(model.parameters()), torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rpMKRptKlac"
   },
   "source": [
    "Или же вот так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "N6mSL4-CKlad",
    "outputId": "d69143af-c39b-4093-93b6-f14f7e9dd420"
   },
   "outputs": [],
   "source": [
    "# Зададим PyTorch модули в качестве словаря\n",
    "model = torch.nn.ModuleDict({\n",
    "    \"linear_1\": torch.nn.Linear(1, 1),\n",
    "    \"linear_2\": torch.nn.Linear(2, 2)\n",
    "})\n",
    "torch.optim.SGD([\n",
    "    {\"params\": model[\"linear_1\"].parameters(), \"lr\": 0.3},\n",
    "    {\"params\": model[\"linear_2\"].parameters()}\n",
    "], lr=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQDxdh1GKlae"
   },
   "source": [
    "Последнее очень полезно для Transfer Learning, когда мы хотим, чтобы предобученная модель тренировалась с другим learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZdZPXYHKlaf"
   },
   "source": [
    "## Делаем свой Optimizer\n",
    "Для того чтобы сделать свой Optimizer, не нужно писать свою имплементацию каждой из основных функций. Достаточно переопределить только одну из них - **step**.\n",
    "\n",
    "Попробуем реализовать несколько своих Optimizer. В качестве данных для модели воспользуемся `make_regression` из `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1b8flzKaKlaf"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    # Зафиксировать seed.\n",
    "    # Это понадобится, чтобы убедиться\n",
    "    # в правильности работы нашего Optimizer\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# make_regression возвращает 2 переменные: данные и таргет для них\n",
    "# так как они возвращаётся как np.array,\n",
    "# вызовем для каждого из них команду torch.from_numpy\n",
    "X, y = map(\n",
    "    lambda x: torch.from_numpy(x).float(),\n",
    "    make_regression(n_samples=200, n_features=2)\n",
    ")\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    # Таким образом, мы при каждом вызове будем получить\n",
    "    # модель с одной и той же инициализацией весов\n",
    "    seed_everything(13)\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(2, 10),\n",
    "        torch.nn.Linear(10, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpeSZshxKlah"
   },
   "source": [
    "Как мы заметили ранее Optimizer работает с группами параметров. Поэтому нам необходимо делать отдельно update для каждой группы параметров (-> ещё один for loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYqWlLS7Klah"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class InClassOptimizer(Optimizer):\n",
    "    def step(self):\n",
    "        \"\"\"Perform a single optimization step.\"\"\"\n",
    "        with torch.no_grad(): # выключим градиенты\n",
    "            for group in self.param_groups:\n",
    "                self._group_step(group)\n",
    "\n",
    "    def _group_step(self, group):\n",
    "        # group ~ dict[str, ...]\n",
    "        \"\"\"\n",
    "        Private helper function to perform\n",
    "        single optimization step on model parameters.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TngP1dBKKlaq"
   },
   "outputs": [],
   "source": [
    "class Adagrad(InClassOptimizer):\n",
    "    def __init__(self, params, lr=0.001, eps=1e-13):\n",
    "        defaults = dict(lr=lr, eps=eps)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    def _group_step(self, group):\n",
    "        # One group contains information about values passed in init\n",
    "        # and model parameters to update\n",
    "        lr = group[\"lr\"]\n",
    "        eps = group[\"eps\"]\n",
    "        for param in filter(lambda x: x.grad is not None, group[\"params\"]):\n",
    "            # TODO:\n",
    "            # Your code here\n",
    "            # --------------\n",
    "            # --------------\n",
    "\n",
    "    def _get_adagrad_buffer(self, param):\n",
    "        \"\"\"\n",
    "        Get accumulated gradients for Adagrad.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        param : `torch.Tensor`, required\n",
    "            Model parameter to get accumulated gradeints for Adagrad.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Accumulated Adagrad gradients for parameter.\n",
    "        \"\"\"\n",
    "        param_state = self.state[param]\n",
    "        \n",
    "        return param_state[\"adagrad_buffer\"]\n",
    "\n",
    "    def _init_adagrad_buffer(self, param):\n",
    "        \"\"\"\n",
    "        Initialize accumulated gradeints for SGD momentum.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        param : `torch.Tensor`, required\n",
    "            Model parameter to get accumulated gradeints for Adagrad.\n",
    "        \"\"\"\n",
    "        param_state = self.state[param]\n",
    "        if \"adagrad_buffer\" not in param_state:\n",
    "            param_state[\"adagrad_buffer\"] = torch.zeros_like(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhojHQMbraUQ"
   },
   "outputs": [],
   "source": [
    "def check_optimizer(model, optim, num_iter):\n",
    "    loss = torch.nn.MSELoss()\n",
    "    for i in range(num_iter):\n",
    "        output = loss(model(X), y.unsqueeze(-1))\n",
    "        output.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i} loss: {output.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl7VOxBeo8qs"
   },
   "source": [
    "Проверим, что написанный Optimizer работает корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "wC70Q3ldKlar",
    "outputId": "7194c3f8-c3e2-41d6-a7a9-ad2faa14df8c"
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "optim = Adagrad(model.parameters(), lr=0.001)\n",
    "check_optimizer(model, optim, num_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "UjOocoLXKlat",
    "outputId": "1dd1ad73-6cf6-4750-ec6b-f77455ac71ff"
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "optim = torch.optim.Adagrad(model.parameters(), lr=0.001)\n",
    "check_optimizer(model, optim, num_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtbewdZwKlat"
   },
   "source": [
    "Почему такой большой лосс?\n",
    "\n",
    "Если посмотреть на optim.state, то сразу становится ясно, что квадраты градиентов очень большие, следовательно, апдейт будет совсем небольшой.\n",
    "\n",
    "Повысим learning rate и посмотрим на поведение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "7iPosGPrpY-3",
    "outputId": "4796c6a7-9b0d-4d41-fa85-18d9c58285f0"
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "optim = Adagrad(model.parameters(), lr=0.1)\n",
    "check_optimizer(model, optim, num_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jyw8oX6vpaO9"
   },
   "source": [
    "`Какая мораль?`\n",
    "\n",
    "Даже если у вас есть методы с адаптивным градиентом спуском, полностью забывать о настройке learning rate не стоит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj75tkPRKlau"
   },
   "source": [
    "## Сравнение методов оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "35c9031b61254fa79548ccdeb8033b1d",
      "7fca95ea86014500b5b7ff3f9716b527",
      "8d434e998b86414abe60209cfeb1a94d",
      "4e3a61f2ee72425db81d1d0a5ed26cb6",
      "fa1704eeeef24136a0ff85fba5a92d75",
      "b00ba37762a14f70a0052be43fa1e8cd",
      "bdd66aafb2304f64b827d829113d6760",
      "41bba40f477942469202cfec13bb7122",
      "c477af2b2463427ba9d8454f64f1dd4b",
      "dfaf08c12b774e48923f8699b1713e3f",
      "85ce744a8d41486397cdd256f641615a",
      "34860a8d426b4fdeb769f4c297d4d13a",
      "cdb38e1ab25b42f7bb23b47342f5d58d",
      "3280df8fa6a44f7086b643a684a3ae93",
      "53d78d6211f14de9a676894fc94c5d56",
      "bad5d97062af495bb202449581fd2441",
      "1ddd97ccef104676873e6f258930982c",
      "20e1b3df12f64b2e9e25ce82ceb91f41",
      "1f80dc949e474e0f989b58cfeff580ac",
      "92b1c924f5a3447c9ad7f6a727ff76f3",
      "3e5268ba20d94371b0382c2862d12582",
      "858001e482e84399bb61d774be1cd721",
      "84aed498131e415f955a12ce2a07e3a6",
      "852f9e67a7db4b3087ce78d6e041ee4c",
      "cb11a043ac4e475b888b6c3c6eb333b3",
      "39c0efe1dd6b456097b96a160e4d47d3",
      "412bc0ed5c4a476581b7a06a33025164",
      "2771f0a068984af38e4bbcf3a028646e",
      "bbd59466f3594fd2829abd6f53cdba06",
      "ab4b4b7858a64cb0adbd1c624bece301",
      "346eed781c83493f9531073cc732f605",
      "520b4c50825841d5b8e719f1ba756998"
     ]
    },
    "id": "hHAHgGdeKlau",
    "outputId": "122ecc5d-368f-452b-90b9-e2ff8955fbb6"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Train data\n",
    "fashion_mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\",\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    fashion_mnist_train, \n",
    "    batch_size=128, \n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Validation data\n",
    "fashion_mnist_eval = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    fashion_mnist_eval, \n",
    "    batch_size=128, \n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr1MKTjBKlaw"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "idx_to_label = defaultdict(lambda: None, {\n",
    "    0: \"T-shirt/Top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Qe43gMTDRz7"
   },
   "outputs": [],
   "source": [
    "class Accuracy:\n",
    "    def __init__(self):\n",
    "        self._all_predictions = torch.LongTensor()\n",
    "        self._all_labels = torch.LongTensor()\n",
    "\n",
    "    def __call__(self, predictions, labels):\n",
    "        # predictions ~ (batch size)\n",
    "        # labels ~ (batch size)\n",
    "        self._all_predictions = torch.cat([\n",
    "            self._all_predictions,\n",
    "            predictions\n",
    "        ], dim=0)\n",
    "        self._all_labels = torch.cat([\n",
    "            self._all_labels,\n",
    "            labels\n",
    "        ], dim=0)\n",
    "\n",
    "    def get_metric(self, reset=False):\n",
    "        correct = (self._all_predictions == self._all_labels).long()\n",
    "        accuracy = correct.sum().float() / self._all_labels.size(0)\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return accuracy\n",
    "\n",
    "    def reset(self):\n",
    "        self._all_predictions = torch.LongTensor()\n",
    "        self._all_labels = torch.LongTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6Mf1W49f2Fv"
   },
   "source": [
    "# Модель\n",
    "\n",
    "1. BatchNorm\n",
    "2. Conv(out=32, kernel=3) -> ReLu -> MaxPool(kernel=2)\n",
    "3. Conv(out=64, kernel=3) -> ReLu -> MaxPool(kernel=2)\n",
    "4. Flatten\n",
    "5. Linear(out=128)\n",
    "6. ReLu\n",
    "7. Dropout\n",
    "8. Linear(out=64)\n",
    "9. ReLu\n",
    "10. Linear(out=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkHmFRSkKlay"
   },
   "outputs": [],
   "source": [
    "class SimpleNetEncoder(torch.nn.Module):\n",
    "    def __init__(self, dropout=0.4):\n",
    "        super().__init__()\n",
    "        # TODO:\n",
    "        # Your code here:\n",
    "        # --------------\n",
    "        # --------------\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO:\n",
    "        # Your code here:\n",
    "        # --------------\n",
    "        # --------------\n",
    "\n",
    "\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super().__init__()\n",
    "        self._encoder = encoder\n",
    "        self._accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        # images ~ (batch size, num channels, height, width)\n",
    "        # target ~ (batch size)\n",
    "        # output ~ (batch size, num classes)\n",
    "        output = self._encoder(images)\n",
    "        output_dict = {\"logits\": output, \"probs\": torch.softmax(output, dim=-1)}\n",
    "        output_dict[\"preds\"] = torch.argmax(output_dict[\"probs\"], dim=-1)\n",
    "        if target is not None:\n",
    "            # CrossEntropy Loss\n",
    "            log_softmax = torch.log_softmax(output, dim=-1)\n",
    "            output_dict[\"loss\"] = F.nll_loss(log_softmax, target)\n",
    "            self._accuracy(\n",
    "                output_dict[\"preds\"].cpu(),\n",
    "                target.cpu()\n",
    "            )\n",
    "        return output_dict\n",
    "\n",
    "    def decode(self, output_dict):\n",
    "        # output_dict ~ dict with torch.Tensors (output_dict from forward)\n",
    "        return [idx_to_label[int(x)] for x in output_dict[\"preds\"]]\n",
    "\n",
    "    def get_metrics(self, reset=False):\n",
    "        return {\"accuracy\": self._accuracy.get_metric(reset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKZRgiLPKlaz"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    return_losses=False,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    model = model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_losses = []\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for batch in data_loader:\n",
    "            # Move Batch to GPU\n",
    "            batch = [x.to(device=device) for x in batch]\n",
    "            output_dict = model(*batch)\n",
    "            loss = output_dict[\"loss\"]\n",
    "            # Update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # Update descirption for tqdm\n",
    "            metrics = model.get_metrics()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(metrics['accuracy'].item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            all_losses.append(loss.detach().item())\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update(model.get_metrics(reset=True))\n",
    "    if return_losses:\n",
    "        return metrics, all_losses\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def validate(model, data_loader, device=\"cuda:0\"):\n",
    "    model = model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for batch in data_loader:\n",
    "            batch = [x.to(device=device, non_blocking=True) for x in batch]\n",
    "            output_dict = model(*batch)\n",
    "            loss = output_dict['loss']\n",
    "            metrics = model.get_metrics()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(metrics['accuracy'].item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update(model.get_metrics(reset=True))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYsKPPGYiySX"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "LossInfo = namedtuple(\n",
    "    \"LossInfo\", \n",
    "    [\"full_train_losses\", \"train_epoch_losses\", \"eval_epoch_losses\"]\n",
    ")\n",
    "\n",
    "\n",
    "EPOCHS = 7\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmOlOzBnKla2"
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    epochs,\n",
    "    train_data_loader,\n",
    "    validation_data_loader,\n",
    "    optimizer,\n",
    "    device\n",
    "):\n",
    "    all_train_losses = []\n",
    "    epoch_train_losses = []\n",
    "    epoch_eval_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        # Construct iterators\n",
    "        train_iterator = iter(train_data_loader)\n",
    "        validation_iterator = iter(validation_data_loader)\n",
    "        # Train step\n",
    "        print(f\"Train Epoch: {epoch}\")\n",
    "        train_metrics, one_epoch_train_losses = train_epoch(\n",
    "            model=model,\n",
    "            data_loader=train_iterator,\n",
    "            optimizer=optimizer,\n",
    "            return_losses=True,\n",
    "            device=device\n",
    "        )\n",
    "        # Save Train losses\n",
    "        all_train_losses.extend(one_epoch_train_losses)\n",
    "        epoch_train_losses.append(train_metrics[\"loss\"])\n",
    "        # Eval step\n",
    "        print(f\"Validation Epoch: {epoch}\")\n",
    "        with torch.no_grad():\n",
    "            validation_metrics = validate(\n",
    "                model=model,\n",
    "                data_loader=validation_iterator,\n",
    "                device=device\n",
    "            )\n",
    "        # Save eval losses\n",
    "        epoch_eval_losses.append(validation_metrics[\"loss\"])\n",
    "    return LossInfo(all_train_losses, epoch_train_losses, epoch_eval_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFpxAPKzX58L"
   },
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Xe-wjJqEXzOY",
    "outputId": "dde3af99-c92c-41b0-8aa9-eb84558a49df",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SimpleNet(encoder=SimpleNetEncoder()).to(device=device)\n",
    "sgd_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=eval_dataloader,\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=LR),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNsHDEOuX_I8"
   },
   "source": [
    "\n",
    "SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WETr80TZXo1Z",
    "outputId": "bc67cdbf-ef1d-435c-b6e3-fb9546deb512",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SimpleNet(encoder=SimpleNetEncoder()).to(device=device)\n",
    "sgd_momentum_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=eval_dataloader,\n",
    "    optimizer=torch.optim.SGD(model.parameters(), momentum=0.9, lr=LR),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ra4g-7ztvBC3"
   },
   "source": [
    "RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pP7tS4gsu_7o",
    "outputId": "6fc9f1ec-869b-4583-dac5-66403f180ec3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SimpleNet(encoder=SimpleNetEncoder()).to(device=device)\n",
    "rmsprop_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=eval_dataloader,\n",
    "    optimizer=torch.optim.RMSprop(model.parameters(), lr=LR),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1-4TFPaYNFP"
   },
   "source": [
    "Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AgDi8etcYKxL",
    "outputId": "9d12ed49-4def-494b-aedd-9e165e8e9c4b"
   },
   "outputs": [],
   "source": [
    "model = SimpleNet(encoder=SimpleNetEncoder()).to(device=device)\n",
    "adam_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=eval_dataloader,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=LR),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "OODJyp5udUmk",
    "outputId": "c42d4d5f-ad28-48ba-acab-dcf331b0daa8"
   },
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * EPOCHS),\n",
    "    sgd_loss_info.full_train_losses,\n",
    "    label=\"SGD\", c=\"grey\"\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * EPOCHS),\n",
    "    sgd_momentum_loss_info.full_train_losses,\n",
    "    label=\"SGD Momentum\", c=\"blue\"\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * EPOCHS),\n",
    "    rmsprop_loss_info.full_train_losses,\n",
    "    label=\"RMSProp\", c=\"green\"\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * EPOCHS),\n",
    "    adam_loss_info.full_train_losses,\n",
    "    label=\"Adam\", c=\"red\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "IjrXHabteGSK",
    "outputId": "2ce69f83-819a-4702-f331-82d08ebeec19"
   },
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    np.arange(EPOCHS), sgd_loss_info.eval_epoch_losses,\n",
    "    label=\"SGD\", c=\"grey\"\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(EPOCHS), sgd_momentum_loss_info.eval_epoch_losses,\n",
    "    label=\"SGD Momentum\", c=\"blue\"\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(EPOCHS), rmsprop_loss_info.eval_epoch_losses,\n",
    "    label=\"RMSprop\", c=\"green\"\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(EPOCHS), adam_loss_info.eval_epoch_losses,\n",
    "    label=\"Adam\", c=\"red\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ixonnU2Kla3"
   },
   "source": [
    "## Оптимизация второго порядка\n",
    "Теперь вернёмся немного назад к функции $f(x)$ и рассмотрим оптимизацию второго порядка [методом Ньютона](https://streletzcoder.ru/nahozhdenit-lokalnyih-ekstremumov-funktsiy-s-pomoshhyu-metoda-nyutona/). Вместо того чтобы приближать функцию в текущей точке линейно можно это делать при помощи квадратов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38Klo8Bp1w33"
   },
   "outputs": [],
   "source": [
    "d_2_func = lambda x: 6 * x - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlCaMEIgKla3"
   },
   "outputs": [],
   "source": [
    "def find_minimum_second_order(eps=1e-4, max_iterations=1000):\n",
    "    i = 0\n",
    "    x_old, x_new = 0, 2\n",
    "    x_list, y_list = [x_old], [func(x_old)]\n",
    "    while abs(x_new - x_old) > eps and i < max_iterations:\n",
    "        # Обновим x_old\n",
    "        x_old = x_new\n",
    "        # Сделаем один шаг gradient descent со 2 порядком градиентов\n",
    "        x_new = x_old - d_func(x_old) / d_2_func(x_old)\n",
    "        # Сохраним значения для визуализации\n",
    "        x_list.append(x_new)\n",
    "        y_list.append(func(x_new))\n",
    "        i += 1\n",
    "    print(\"Найденный локальный минимум:\", x_new)\n",
    "    print(\"Количество шагов:\", len(x_list))\n",
    "    # Визуализируем сходимость\n",
    "    plt.figure(figsize=[6, 4])\n",
    "    plt.ylim([-3, 8])\n",
    "    plt.scatter(x_list, y_list, c=\"r\", edgecolors=\"k\")\n",
    "    plt.plot(x_list, y_list, c=\"r\")\n",
    "    plt.plot(x, func(x), c=\"b\")\n",
    "    plt.title(\"Descent trajectory\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "OJChBOk3Kla5",
    "outputId": "6299fb2d-4992-47e5-ecbd-25a82d892101"
   },
   "outputs": [],
   "source": [
    "find_minimum_second_order()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idTHdfv7Kla6"
   },
   "source": [
    "В итоге мы пришли к минимуму гораздо быстрее. И если же методы второго порядка такие крутые и быстрые, то почему их не используют в нейронных сетях? Для ответа на этот вопрос сначала рассмотрим плюсы и минусы данного подхода.\n",
    "\n",
    "Плюсы методов второго порядка:\n",
    "* Быстрее, чем методы оптимизации первого порядка\n",
    "* Нет необходимости настраивать learning_rate\n",
    "\n",
    "Можете ли вы предположить минусы методов оптимизации второго порядка или же просто методов Ньютона?\n",
    "\n",
    "Ответ:\n",
    "* Сложность вычисления градиента второго порядка\n",
    "* В многомерном случае необходимо хранить матрицу размерности N x N\n",
    "\n",
    "Проблема с памятью наиболее острая, так как современные нейронные сети имеют миллионы параметров и хранить матрицу миллион на миллион очень сложно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEcFfzhaKla6"
   },
   "source": [
    "## Зачем мы вообще начали разговор о 2 порядке?\n",
    "Ответ в том, что методы с адаптивными градиентным являются аппроксимацией методов 2 порядка. Отсюда становится понятно, почему мы делим на матрицу квадратов в Adagrad и других его модификациях\n",
    "$$\n",
    "\\mathbb{E}[gg^{T}] \\sim \\mathbb{E}[H(x)]\n",
    "$$\n",
    "Здесь:\n",
    "* $gg^{T}$ - квадратная матрица квадратов градиентов\n",
    "* $\\mathbb{E}[H(x)]$ - ожидаемое значение Гессиана (матрица градиентов 2 порядка). В адаптивном градиенте разница лишь в том, что мы берём $\\sqrt{diag(gg^{T})}$, так как $gg^{T}$ занимает слишком много места."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar_optimization.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ddd97ccef104676873e6f258930982c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f80dc949e474e0f989b58cfeff580ac",
       "IPY_MODEL_92b1c924f5a3447c9ad7f6a727ff76f3"
      ],
      "layout": "IPY_MODEL_20e1b3df12f64b2e9e25ce82ceb91f41"
     }
    },
    "1f80dc949e474e0f989b58cfeff580ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_858001e482e84399bb61d774be1cd721",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e5268ba20d94371b0382c2862d12582",
      "value": 1
     }
    },
    "20e1b3df12f64b2e9e25ce82ceb91f41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2771f0a068984af38e4bbcf3a028646e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_520b4c50825841d5b8e719f1ba756998",
      "placeholder": "​",
      "style": "IPY_MODEL_346eed781c83493f9531073cc732f605",
      "value": " 8192/? [00:00&lt;00:00, 21363.43it/s]"
     }
    },
    "3280df8fa6a44f7086b643a684a3ae93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "346eed781c83493f9531073cc732f605": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34860a8d426b4fdeb769f4c297d4d13a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bad5d97062af495bb202449581fd2441",
      "placeholder": "​",
      "style": "IPY_MODEL_53d78d6211f14de9a676894fc94c5d56",
      "value": " 32768/? [00:02&lt;00:00, 13502.77it/s]"
     }
    },
    "35c9031b61254fa79548ccdeb8033b1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d434e998b86414abe60209cfeb1a94d",
       "IPY_MODEL_4e3a61f2ee72425db81d1d0a5ed26cb6"
      ],
      "layout": "IPY_MODEL_7fca95ea86014500b5b7ff3f9716b527"
     }
    },
    "39c0efe1dd6b456097b96a160e4d47d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e5268ba20d94371b0382c2862d12582": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "412bc0ed5c4a476581b7a06a33025164": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab4b4b7858a64cb0adbd1c624bece301",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bbd59466f3594fd2829abd6f53cdba06",
      "value": 1
     }
    },
    "41bba40f477942469202cfec13bb7122": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e3a61f2ee72425db81d1d0a5ed26cb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41bba40f477942469202cfec13bb7122",
      "placeholder": "​",
      "style": "IPY_MODEL_bdd66aafb2304f64b827d829113d6760",
      "value": " 26427392/? [10:57&lt;00:00, 40206.55it/s]"
     }
    },
    "520b4c50825841d5b8e719f1ba756998": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53d78d6211f14de9a676894fc94c5d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fca95ea86014500b5b7ff3f9716b527": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84aed498131e415f955a12ce2a07e3a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "852f9e67a7db4b3087ce78d6e041ee4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "858001e482e84399bb61d774be1cd721": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85ce744a8d41486397cdd256f641615a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3280df8fa6a44f7086b643a684a3ae93",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdb38e1ab25b42f7bb23b47342f5d58d",
      "value": 1
     }
    },
    "8d434e998b86414abe60209cfeb1a94d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b00ba37762a14f70a0052be43fa1e8cd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fa1704eeeef24136a0ff85fba5a92d75",
      "value": 1
     }
    },
    "92b1c924f5a3447c9ad7f6a727ff76f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_852f9e67a7db4b3087ce78d6e041ee4c",
      "placeholder": "​",
      "style": "IPY_MODEL_84aed498131e415f955a12ce2a07e3a6",
      "value": " 4423680/? [00:01&lt;00:00, 2326903.53it/s]"
     }
    },
    "ab4b4b7858a64cb0adbd1c624bece301": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b00ba37762a14f70a0052be43fa1e8cd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad5d97062af495bb202449581fd2441": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbd59466f3594fd2829abd6f53cdba06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bdd66aafb2304f64b827d829113d6760": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c477af2b2463427ba9d8454f64f1dd4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85ce744a8d41486397cdd256f641615a",
       "IPY_MODEL_34860a8d426b4fdeb769f4c297d4d13a"
      ],
      "layout": "IPY_MODEL_dfaf08c12b774e48923f8699b1713e3f"
     }
    },
    "cb11a043ac4e475b888b6c3c6eb333b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_412bc0ed5c4a476581b7a06a33025164",
       "IPY_MODEL_2771f0a068984af38e4bbcf3a028646e"
      ],
      "layout": "IPY_MODEL_39c0efe1dd6b456097b96a160e4d47d3"
     }
    },
    "cdb38e1ab25b42f7bb23b47342f5d58d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dfaf08c12b774e48923f8699b1713e3f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa1704eeeef24136a0ff85fba5a92d75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
