{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "sem_n1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96590766145149d5a8dfa007061eea8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_564e8a2570774f15a4aace01e052d88a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a453bcdcea24b218d81936326e7415c",
              "IPY_MODEL_f12cc35499b640b1b874d64e7c24fa1c",
              "IPY_MODEL_20bc56f5a5da4549800a7ba1f491411c"
            ]
          }
        },
        "564e8a2570774f15a4aace01e052d88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a453bcdcea24b218d81936326e7415c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef8b89ad325144918125895df1a87903",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Loss: 0.8057 Accuracy: 100.0:  15%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5388ce2acbd9421d8dc5b9cf72aa0934"
          }
        },
        "f12cc35499b640b1b874d64e7c24fa1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5dfbf2f9e9954d47b4ccafad7f1a4d54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 782,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 116,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89f8839174894f9f90a0100901b44016"
          }
        },
        "20bc56f5a5da4549800a7ba1f491411c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_896a7c58d8c64bda886b2c845469c413",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 116/782 [00:06&lt;00:48, 13.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f80042bd044450bab50bad5c2fed3ec"
          }
        },
        "ef8b89ad325144918125895df1a87903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5388ce2acbd9421d8dc5b9cf72aa0934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dfbf2f9e9954d47b4ccafad7f1a4d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89f8839174894f9f90a0100901b44016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "896a7c58d8c64bda886b2c845469c413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f80042bd044450bab50bad5c2fed3ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06d340bf"
      },
      "source": [
        "# Семинар 9. Классификация последовательностей (текстов) -- good practices\n",
        "\n",
        "На прошлом семинаре мы рассмотрели пример генерации текстов. Однако мы не обсудили весь огромный функционал, который предоставляет пайторч для работы с текстами. В частности работали мы с посимвольной генерацией, а не пословной/потокенной. Исправляемся!\n",
        "\n",
        "Сегодня речь зайдёт о задаче классификации текстовых последовательностей. Для этого будем пользоваться датасетом IMDB и библиотекой `torchtext`. В торчтексте реализовано огромное число методов для обработки текстов, ими мы и воспользуемся.\n",
        "\n",
        "__АХТУНГ__. Торчтекст не рекомендуется использовать для обучения на больших данных (от миллиона примеров и больше) из-за маленькой скорости работы. В таких случаях рекомендуется имплементировать свои датасеты. В наших примерах таких объёмов данных не будет."
      ],
      "id": "06d340bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac5cd1db"
      },
      "source": [
        "## Начнём с модели.\n",
        "\n",
        "Да, не самая привыичная последовательность действий, но давайте сначала сделаем кое-что, с чем мы уже знакомы -- имплементируем модель.\n",
        "\n",
        "На вход она будет принимать батч последовательностей токенов, разумеется разной длины в разных батчах, а на выходе выдавать батч вероятностей классов, прямо как в классификации картинок.\n",
        "\n",
        "Каждый токен пройдёт вначале через эмбеддинг, а затем последовательность эмбеддингов пройдёт через LSTM. Самое последнее скрытое состояние будем считать векторным представлением для последовательности, поверх неё мы навесим линейный слой."
      ],
      "id": "ac5cd1db"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88a7a3b1"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, num_embeddings=25002, embedding_size=300, hidden_size=200, num_classes=2, num_layers=1):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.embedding = # YOUR CODE\n",
        "        self.lstm = # YOUR CODE\n",
        "        self.linear = # YOUR CODE\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, (last_hidden, last_c) = self.lstm(embedded)\n",
        "        return self.linear(last_hidden[0]).squeeze()\n",
        "\n",
        "model = TextClassifier()"
      ],
      "id": "88a7a3b1",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff2c5c61",
        "outputId": "16cc9774-eb02-4bbe-ca05-4bbae0b33ad7"
      },
      "source": [
        "model(torch.tensor([[1,2,3,4], [1,2,3,4]]))"
      ],
      "id": "ff2c5c61",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2758, 0.2758], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73797236"
      },
      "source": [
        "## Скачаем и проинициализируем датасет\n",
        "\n",
        "Дальше перейдём к торчтексту. Он почти как знакомый нам `torchvision` имеет внутри себя коллекцию датасетов для разных задач NLP в том числе и отзывы на IMDB. Инициализация датасета порой занимает время, не следует волноваться и судорожно перезапускать ядро."
      ],
      "id": "73797236"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ddfb36e"
      },
      "source": [
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy.datasets import IMDB\n"
      ],
      "id": "4ddfb36e",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "444cf930"
      },
      "source": [
        "# spacy -- вспомогательная библоитека для токенизации текста, скачаем токенайзер для английского языка\n",
        "! pip install spacy\n",
        "! python -m spacy download en_core_web_sm"
      ],
      "id": "444cf930",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f73f01f"
      },
      "source": [
        "В `torchtext` существует такая сущность, как `Field`. Это просто класс, в котором содержится описание колонок нашего датасета. В нашем случае всё довольно просто. Есть две колонки --- это текст и оценка, назовём их `text_field` и `label_field` соответственно. Токенизовать будем при помощи установленной только что библиотеки `spacy`, лейблы приведём к типу `float`. Разумеется, как и на прошлом семинаре ставим batch_first=False."
      ],
      "id": "2f73f01f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ace08bb"
      },
      "source": [
        "\n",
        "text_field = data.Field(tokenize='spacy',\n",
        "                        batch_first=True,\n",
        "                        include_lengths=False,\n",
        "                        tokenizer_language='en_core_web_sm')\n",
        "\n",
        "label_field = data.LabelField(dtype=torch.float32, batch_first=True)\n",
        "\n"
      ],
      "id": "7ace08bb",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4ea62e"
      },
      "source": [
        "Создадим два сплита нашего датасета. Они задаются при помощи метода splits."
      ],
      "id": "ee4ea62e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27834eb",
        "outputId": "b9db8caf-de79-4f55-ee01-ae86c8fd1e91"
      },
      "source": [
        "data_train, data_test = IMDB.splits(text_field, label_field)"
      ],
      "id": "c27834eb",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84.1M/84.1M [00:06<00:00, 13.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2120f86"
      },
      "source": [
        "Создадим также словари, соответствующие нашему тексту. Выкинем все слова (токены), которые встречаются редко. Оставим только 25 тысяч самых частых слов.\n",
        "\n",
        "Также согласуем номера токенов в словаре с предобученными эмбеддингами glove. Они называются `glove.6B.100d`, то есть 100-мерные и обученные на 6 миллиардах документов. При желании можно согласовать и с word2vec'ом, но имейте ввиду, что glove это их аналог. Об инициализации эмбеддингов мы обязательно поговорим чуть позже."
      ],
      "id": "c2120f86"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d142a6af",
        "outputId": "0214340d-ebcb-4202-ed05-ed14e53fb507"
      },
      "source": [
        "vocab_size = 25000\n",
        "\n",
        "# build_vocab -- создать словарь по данному полю в датасете\n",
        "text_field.build_vocab(data_train,\n",
        "                       max_size=vocab_size,\n",
        "                       vectors=\"glove.6B.100d\",\n",
        "                      )\n",
        "\n",
        "label_field.build_vocab(data_train)\n",
        "\n",
        "\n",
        "for item in data_train:\n",
        "    print(item.text)\n",
        "    break"
      ],
      "id": "d142a6af",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:47, 5.14MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:22<00:00, 18096.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cheech', '&', 'Chong', \"'s\", 'Next', 'Movie', '(', '1980', ')', 'was', 'the', 'second', 'film', 'to', 'star', 'to', 'pot', 'loving', 'duo', 'of', 'Cheech', 'Marin', 'and', 'Tommy', 'Chong', '.', 'The', 'lovable', 'burn', 'out', 'smokers', 'are', 'now', 'roommates', '.', 'They', 'live', 'in', 'a', 'condemned', 'building', 'looking', 'for', 'ways', 'to', 'score', 'more', 'smoke', 'and', 'just', 'lay', 'about', 'all', 'day', '.', 'But', 'Cheech', 'is', 'the', '\"', 'responsible', '\"', 'one', '.', 'He', 'has', 'a', 'job', 'and', 'a', 'steady', 'girlfriend', '.', 'One', 'day', ',', 'Cheech', 'wants', 'to', 'get', 'his', 'freak', 'on', 'so', 'he', 'tries', 'to', 'get', 'Chong', 'out', 'of', 'the', 'house', '.', 'Another', 'problem', 'arises', 'as', 'well', ',', 'Cheech', \"'s\", 'brother', '\"', 'Red', '\"', '(', 'Cheech', 'is', 'another', 'role', ')', 'is', 'in', 'town', 'and', 'wants', 'to', 'hang', 'with', 'him', '.', 'Firguring', 'that', 'he', 'could', 'kill', 'two', 'birds', 'with', 'one', 'stone', ',', 'Cheech', 'pawns', 'Chong', 'off', 'and', 'Red', '.', 'What', 'kind', 'of', 'adventures', 'will', 'Chong', 'and', 'Red', 'get', 'into', '?', 'Will', 'Cheech', 'get', 'his', 'freak', 'on', '?', 'How', 'long', 'will', 'Chong', 'go', 'without', 'some', 'smoke', '?', 'Just', 'watch', 'CHEECH', '&', 'CHONG', \"'S\", 'NEXT', 'MOVIE', 'to', 'find', 'out!!<br', '/><br', '/>Tommy', 'Chong', 'takes', 'over', 'the', 'directorial', 'reigns', 'for', 'the', 'sequel', '.', 'He', 'received', 'some', 'experience', 'when', 'he', 'did', 'some', 'uncredited', 'work', 'on', 'UP', 'IN', 'SMOKE', '.', 'Funny', 'but', 'not', 'as', 'good', 'as', 'the', 'first', 'film', '.', 'But', 'Cheech', 'and', 'Chong', 'fans', 'will', 'enjoy', 'it', '.', 'Followed', 'by', 'NICE', 'DREAMS.<br', '/><br', '/>Recommended', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "022be96a"
      },
      "source": [
        "Давайте посмотрим на самые частые токены в словаре."
      ],
      "id": "022be96a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2932700",
        "outputId": "17e58650-ca7f-49d1-a8de-42c0d4967bcb"
      },
      "source": [
        "text_field.vocab.freqs.most_common(10)"
      ],
      "id": "d2932700",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 289838),\n",
              " (',', 275296),\n",
              " ('.', 236843),\n",
              " ('and', 156483),\n",
              " ('a', 156282),\n",
              " ('of', 144055),\n",
              " ('to', 133886),\n",
              " ('is', 109095),\n",
              " ('in', 87676),\n",
              " ('I', 77546)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6c62077",
        "outputId": "8d889870-8227-4d84-e190-f16026f20904"
      },
      "source": [
        "# itos -- index to string\n",
        "text_field.vocab.itos[:10]"
      ],
      "id": "e6c62077",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a5c4e29"
      },
      "source": [
        "Как мы видим, в поле текста у нас стоят токены, на которые поделил spacy поделил текст! Осталось только воспользоваться построенным словарём и сделать аналог даталоадера по данным!"
      ],
      "id": "5a5c4e29"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c2e38b7"
      },
      "source": [
        "train_dataloader, test_dataloader = data.BucketIterator.splits((data_train, data_test), batch_size=32, device=\"cuda:0\")\n"
      ],
      "id": "5c2e38b7",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d042926",
        "outputId": "7783ad29-2796-4e50-deba-0112bd262d9f"
      },
      "source": [
        "for item in train_dataloader:\n",
        "    print(item.text.shape, item.label.shape)\n",
        "    break"
      ],
      "id": "9d042926",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1263]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5379f8d4"
      },
      "source": [
        "Длина текста довольно большая, и при желании можно обрезать тексты."
      ],
      "id": "5379f8d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "366c2675"
      },
      "source": [
        "## Train loop\n",
        "\n",
        "Перейдём к самому интересному (нет) и построим трейн луп к нашей модели. Но скажем сразу, он мало чем будет отличаться от классификации картинок."
      ],
      "id": "366c2675"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "566445fc"
      },
      "source": [
        "def train_epoch(\n",
        "    model,\n",
        "    data_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    return_losses=False,\n",
        "    device=\"cuda:0\",\n",
        "):\n",
        "    model = model.to(device).train()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    all_losses = []\n",
        "    total_predictions = np.array([])#.reshape((0, ))\n",
        "    total_labels = np.array([])#.reshape((0, ))\n",
        "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
        "        for item in data_loader:\n",
        "            images = item.text\n",
        "            labels = item.label\n",
        "\n",
        "            # Move Batch to GPU\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "            loss = criterion(predicted, labels)\n",
        "            # Update weights\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # Update descirption for tqdm\n",
        "            accuracy = ((predicted > 0.5).int() == labels).float().mean()\n",
        "            prbar.set_description(\n",
        "                f\"Loss: {round(loss.item(), 4)} \"\n",
        "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
        "            )\n",
        "            prbar.update(1)\n",
        "            total_loss += loss.item()\n",
        "            total_predictions = np.append(total_predictions,(predicted > 0.5).int().cpu().detach().numpy())\n",
        "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "            num_batches += 1\n",
        "            all_losses.append(loss.detach().item())\n",
        "    metrics = {\"loss\": total_loss / num_batches}\n",
        "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
        "    if return_losses:\n",
        "        return metrics, all_losses\n",
        "    else:\n",
        "        return metrics\n",
        "\n",
        "\n",
        "def validate(model, data_loader, criterion, device=\"cuda:0\"):\n",
        "    model = model.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    total_predictions = np.array([])\n",
        "    total_labels = np.array([])\n",
        "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
        "        for item in data_loader:\n",
        "            images = item.text\n",
        "            labels = item.label\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            predicted = model(images)\n",
        "            loss = criterion(predicted, labels)\n",
        "            accuracy = ((predicted > 0.5).int() == labels).float().mean()\n",
        "            prbar.set_description(\n",
        "                f\"Loss: {round(loss.item(), 4)} \"\n",
        "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
        "            )\n",
        "            prbar.update(1)\n",
        "            total_loss += loss.item()\n",
        "            total_predictions = np.append(total_predictions, (predicted > 0.5).int().cpu().detach().numpy())\n",
        "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
        "            num_batches += 1\n",
        "    metrics = {\"loss\": total_loss / num_batches}\n",
        "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
        "    return metrics"
      ],
      "id": "566445fc",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "96590766145149d5a8dfa007061eea8e",
            "564e8a2570774f15a4aace01e052d88a",
            "3a453bcdcea24b218d81936326e7415c",
            "f12cc35499b640b1b874d64e7c24fa1c",
            "20bc56f5a5da4549800a7ba1f491411c",
            "ef8b89ad325144918125895df1a87903",
            "5388ce2acbd9421d8dc5b9cf72aa0934",
            "5dfbf2f9e9954d47b4ccafad7f1a4d54",
            "89f8839174894f9f90a0100901b44016",
            "896a7c58d8c64bda886b2c845469c413",
            "8f80042bd044450bab50bad5c2fed3ec"
          ]
        },
        "id": "sLa83CXsHAOe",
        "outputId": "b9cb1203-1779-4de0-c080-6dd1e90fe1d2"
      },
      "source": [
        ""
      ],
      "id": "sLa83CXsHAOe",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96590766145149d5a8dfa007061eea8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/782 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-53f2e563ee05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-42a22af51b45>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, data_loader, criterion, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             prbar.set_description(\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;34mf\"Loss: {round(loss.item(), 4)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;34mf\"Accuracy: {round(accuracy.item() * 100, 4)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a9825e1"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "\n",
        "device=\"cuda:0\"\n",
        "model = TextClassifier()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for i in range(10):\n",
        "    train_epoch(model, train_dataloader, criterion=criterion, optimizer=optimizer, device=device)\n",
        "    validate(model, test_dataloader, criterion, device)"
      ],
      "id": "6a9825e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EttH3QDVcVnE"
      },
      "source": [
        "Кажется, обучается так себе. Давайте это исправлять! \n",
        "\n",
        "Потенциальных исправлений, которые должны повлиять на ход обучения несколько:\n",
        "\n",
        "- Сделать модель двунаправленной\n",
        "- увеличить число слоёв (народная мудрость машинлёрнеров!)\n",
        "- Добавить регуляризацию (dropout на эмбеддинги)\n",
        "- Проинициализировать эмбеддинги при помощи glove.\n",
        "\n",
        "\n",
        "Заметим, что в двунаправленной модели размерность выхода есть `[d * num_layers, batch_size, hidden_size]`, так что будем брать начальное и конечное состояние двунаправленной сети с последнего слоя и конкатенировать их в один вектор-представление для предложения."
      ],
      "id": "EttH3QDVcVnE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvua6cZRcU2h"
      },
      "source": [
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, num_embeddings=25002, embedding_size=300, hidden_size=200, num_classes=2, num_layers=1, pad_token=1):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.embedding = # YOUR CODE\n",
        "        self.lstm = # YOUR CODE\n",
        "        self.linear = # YOUR CODE\n",
        "        self.dropout = # YOUR CODE\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        _, (last_hidden, last_c) = self.lstm(embedded)\n",
        "        # last_hidden.shape == [2 * num_layers, batch_size, hidden_size]\n",
        "        # Далее просто конкатенируем два последних состояния в один тензор\n",
        "        hidden = torch.cat([last_hidden[-2], last_hidden[-1]], dim=1)\n",
        "        return self.linear(hidden).squeeze()\n",
        "\n",
        "device=\"cuda:0\"\n",
        "pad_token = text_field.vocab.stoi['<pad>']\n",
        "model = TextClassifier(hidden_size=512, embedding_size=100, num_layers=2, pad_token=pad_token)\n",
        "model.embedding.weight.data = text_field.vocab.vectors\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model(torch.tensor([[1,2,3,4], [1,2,3,4]]))\n",
        "\n",
        "for i in range(10):\n",
        "    train_epoch(model, train_dataloader, criterion=criterion, optimizer=optimizer, device=device)\n",
        "\n"
      ],
      "id": "Dvua6cZRcU2h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbKrLaPUIXZT"
      },
      "source": [
        "Вот так-то лучше!"
      ],
      "id": "fbKrLaPUIXZT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "336be296"
      },
      "source": [
        ""
      ],
      "id": "336be296",
      "execution_count": null,
      "outputs": []
    }
  ]
}